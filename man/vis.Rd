% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/largeVis.R
\name{vis}
\alias{vis}
\title{Apply the LargeVis algorithm for visualizing large high-dimensional datasets.}
\usage{
vis(x, dim = 2, K = 40, check.assumptions = TRUE, n_trees = 50,
  tree_threshold = max(10, ncol(x)), max_iter = 3, perplexity = 50,
  sgd_batches = nrow(x) * 20000, M = 5, weight_pos_samples = TRUE,
  alpha = 2, gamma = 7, rho = 1, min_rho = 0, coords = NULL,
  verbose = TRUE, ...)
}
\arguments{
\item{x}{A matrix. Ideally, the columns should be scaled and normalized to avoid the risk of errors caused by overflow.}

\item{dim}{The number of dimensions in the output}

\item{K}{The number of nearest-neighbors to use in computing the kNN graph}

\item{check.assumptions}{Whether to check the input matrix for duplicates, \code{NA}`s, etc.}

\item{n_trees}{See \code{\link{randomProjectionTreeSearch}}.  The default is set at 50, which is the number
used in the examples in the original paper.}

\item{tree_threshold}{See \code{\link{randomProjectionTreeSearch}}.  By default, this is the number of features
in the input set, which is the setting used in the examples in the original paper.  Note the time and memory requirements:
the first pass through the neighborhood exploration phases will involve up to \eqn{N * nTrees * threshold} comparisons.}

\item{max_iter}{See \code{\link{randomProjectionTreeSearch}}.}

\item{perplexity}{See paper}

\item{sgd_batches}{See \code{\link{projectKNNs}}.}

\item{M}{See \code{\link{projectKNNs}}.}

\item{weight_pos_samples}{See \code{\link{projectKNNs}}.}

\item{alpha}{See \code{\link{projectKNNs}}.}

\item{gamma}{See \code{\link{projectKNNs}}.}

\item{rho}{See \code{\link{projectKNNs}}.}

\item{min_rho}{\code{\link{projectKNNs}}.}

\item{coords}{A [N,K] matrix of coordinates to use as a starting point -- useful for refining an embedding in stages.}

\item{verbose}{Verbosity}

\item{...}{See paper}
}
\value{
A `largeVis` object with the following slots:
 \itemize{
   \item{'knns'} {An [N,K] integer matrix, which is an adjacency list of each vertex' identified nearest neighbors.
   If the algorithm failed to find \code{K} neighbors, the matrix is padded with \code{NA}'s.}
   \item{'wij'} {A sparse [N,N] matrix where each cell represents \eqn{w_{ij}}.}
   \item{'call'}
   \item{'coords'} {A [N,D] matrix of the embedding of the dataset in the low-dimensional space.}
 }
}
\description{
Implements the \code{vis}
}
\details{
Note that this implementation expects the data to be free of \code{NaN}'s, \code{NA}'s, \code{Inf}'s, and duplicate rows.
If any of these assumptions are violated, the algorithm will fail. It is also usually a good idea to scale the input data
to have unit norm and mean 0. If there are large values in the input matrix, some computations may oveflow.
}
\examples{
# iris
data(iris)
dat <- as.matrix(iris[,1:4])
dat <- scale(dat)
dupes = which(duplicated(dat))
dat <- dat[-dupes,] # duplicated data potentially can cause the algorithm to fail
visObject <- vis(dat, max_iter = 20, sgd_batches = 800000,
                     K = 10,  gamma = 2, rho = 1, M = 40, alpha = 20,verbose=FALSE)
\dontrun{
# mnist
load("./mnist.Rda")
dat <- mnist$images
dim(dat) <- c(42000, 28 * 28)
dat <- (dat / 255) - 0.5
coords <- vis(dat, n.tree = 10, tree_threshold = 40,
                     K = 40, sgd = 20000 * 42000, alpha = 1, max_iter = 10)
}

}
\references{
Jian Tang, Jingzhou Liu, Ming Zhang, Qiaozhu Mei. \href{https://arxiv.org/abs/1602.00370}{Visualizing Large-scale and High-dimensional Data.}
}

